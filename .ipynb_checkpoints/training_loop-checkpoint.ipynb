{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "744e20b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import Accuracy\n",
    "\n",
    "tfd = tfp.distributions\n",
    "tfpl = tfp.layers\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from collections import deque\n",
    "import random\n",
    "import sys\n",
    "\n",
    "from tictactoe.game import TicTacToe\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "239b1d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.join('tictactoe'))\n",
    "from tictactoe import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c2adc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import models\n",
    "from models import RecurrentNetwork as rn\n",
    "\n",
    "#initialize model\n",
    "# model = rn.RecurrentNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0406ae03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the learning rate schedule function\n",
    "# def lr_schedule(epoch):\n",
    "#     # Initially high learning rate, and decay it gradually\n",
    "#     initial_lr = initial_learning_rate\n",
    "#     decay_factor = 0.1\n",
    "#     decay_epochs = 10  # Adjust the number of epochs after which to decay the learning rate\n",
    "    \n",
    "#     if epoch < decay_epochs:\n",
    "#         return initial_lr\n",
    "#     else:\n",
    "#         return initial_lr * (decay_factor ** (epoch // decay_epochs))\n",
    "\n",
    "# # lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lr_schedule)\n",
    "# initial_learning_rate = 0.001\n",
    "# optimizer = Adam(learning_rate = initial_learning_rate)\n",
    "# model.compile(loss = 'mean_squared_error', optimizer = optimizer)\n",
    "# model.build(input_shape = (None, 3, 3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8df36f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d68187c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #simpler model\n",
    "# model = tf.keras.Sequential([\n",
    "#     tf.keras.layers.Flatten(input_shape=(3, 3, 3)),  # Flatten the 3x3x3 input\n",
    "#     tf.keras.layers.Dense(128, activation='relu'),\n",
    "#     tf.keras.layers.Dense(64, activation='relu'),\n",
    "#     tf.keras.layers.Dense(32, activation='relu'),\n",
    "#     tf.keras.layers.Dense(16, activation='relu'),\n",
    "#     tf.keras.layers.Dense(9, activation='linear')   # Output layer with 9 units for the Q-values\n",
    "# ])\n",
    "\n",
    "# learning_rate = 0.001\n",
    "\n",
    "# # Compile the model\n",
    "# model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "#                     loss='mse')  # Mean Squared Error is commonly used in Q-Learning\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "84282cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_block_10 (ConvBlock)    (None, 3, 3, 64)          2048      \n",
      "_________________________________________________________________\n",
      "conv_block_11 (ConvBlock)    (None, 3, 3, 64)          37184     \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 128)               73856     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 9)                 297       \n",
      "=================================================================\n",
      "Total params: 123,721\n",
      "Trainable params: 123,465\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create a new model using 2D Convolutional layers\n",
    "model = tf.keras.Sequential([\n",
    "    rn.ConvBlock(3, 64, kernel_size = 3),\n",
    "    rn.ConvBlock(3, 64, kernel_size = 3),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128),\n",
    "    tf.keras.layers.Dense(64),\n",
    "    tf.keras.layers.Dense(32),\n",
    "    tf.keras.layers.Dense(9, activation='tanh')   # Output layer with 9 units for the Q-values\n",
    "])\n",
    "\n",
    "# Compile the new 2D Convolutional model\n",
    "learning_rate = 0.01\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                   loss='mse')  # Mean Squared Error is commonly used in Q-Learning\n",
    "model.build(input_shape = (None, 3, 3, 3))\n",
    "# Summary of the new model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ae352578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| X | O |   |\n",
      "| X | O |   |\n",
      "|   |   |   |\n"
     ]
    }
   ],
   "source": [
    "#print out some states and the responses by the model\n",
    "#example state\n",
    "ttt = TicTacToe()\n",
    "ttt.play_move(0, 0, False)\n",
    "ttt.play_move(0, 1, False)\n",
    "ttt.play_move(1, 0, False)\n",
    "ttt.play_move(1, 1, True)\n",
    "\n",
    "sample_state_1 = train.board_state_int(ttt.board, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d9f0e453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   | O | X |\n",
      "|   | X |   |\n",
      "|   |   | O |\n"
     ]
    }
   ],
   "source": [
    "ttt = TicTacToe()\n",
    "\n",
    "ttt.play_move(0, 2, False)\n",
    "ttt.play_move(0, 1, False)\n",
    "ttt.play_move(1, 1, False)\n",
    "ttt.play_move(2, 2)\n",
    "\n",
    "sample_state_2 = train.board_state_int(ttt.board, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1903ea33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.06701357, -0.00605297, -0.27957124,  0.0646374 , -0.06643933,\n",
       "        -0.01312321, -0.23372096,  0.09830277,  0.13822438]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(sample_state_2[np.newaxis, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c8097e03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#variables\n",
    "gamma = 0.9\n",
    "reward_value = 1\n",
    "epsilon = 0.5\n",
    "epsilon_min = 0.1\n",
    "epsilon_decay = 0.001\n",
    "memory = deque(maxlen = 32)\n",
    "batch_size = 32\n",
    "episodes = 1000\n",
    "save_dir = os.path.join('model_weights', 'RecurrentNetwork')\n",
    "device = tf.test.gpu_device_name()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4eded004",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training loop\n",
    "# if len(memory) > batch_size:\n",
    "\n",
    "#     memory_list = list(memory)\n",
    "#     mini_batch = random.sample(memory_list, batch_size)\n",
    "\n",
    "#     inputs = tf.zeros((batch_size, state.shape[0], state.shape[1], state.shape[2]))\n",
    "#     outputs = tf.zeros((batch_size, 9)) #9 is the number of values\n",
    "\n",
    "#     #get stuff from the mini batch and get qu values and stuff\n",
    "#     for i, (cs, ns, mv, r) in enumerate(mini_batch):\n",
    "#         with tf.device(device):\n",
    "#             q_value = r + gamma * tf.reduce_max(model.predict(ns[np.newaxis, :]))\n",
    "#             #predicted q values\n",
    "#             pred_q_values = model.predict(cs[np.newaxis, :])\n",
    "\n",
    "#         #add the new q value\n",
    "#         move_int = train.cell_to_int_dict[mv]\n",
    "#         pred_q_values[0][move_int] = q_value\n",
    "\n",
    "# #             print(move_int, pred_q_values, r)\n",
    "\n",
    "#         inputs = tf.tensor_scatter_nd_update(inputs, [[i]], [cs])  \n",
    "#         outputs = tf.tensor_scatter_nd_update(outputs, [[i]], [pred_q_values.ravel()]) \n",
    "\n",
    "#     model.fit(inputs, outputs, verbose = 0, epochs = 1, callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "40bb1ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train model\n",
    "# train.training_loop(model, memory, epsilon, gamma, save_dir = save_dir, device = device, save_model_every = 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cbdf9e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current episode: 0\n",
      "sample one: 7 max q val = 0.23241658508777618\n",
      "sample two: 8 max q val = 0.13822437822818756\n",
      "current episode: 10\n",
      "sample one: 1 max q val = 1.0\n",
      "sample two: 1 max q val = 1.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-f43958425dd3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     81\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmini_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m                     \u001b[0mq_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mgamma\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_max\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m                     \u001b[1;31m#predicted q values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m                     \u001b[0mpred_q_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1596\u001b[0m                         '. Consider setting it to AutoShardPolicy.DATA.')\n\u001b[0;32m   1597\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1598\u001b[1;33m       data_handler = data_adapter.DataHandler(\n\u001b[0m\u001b[0;32m   1599\u001b[0m           \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1600\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m     self._adapter = adapter_cls(\n\u001b[0m\u001b[0;32m   1101\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    351\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mflat_dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 353\u001b[1;33m     \u001b[0mindices_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflat_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslice_batch_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    354\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mslice_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mflat_map\u001b[1;34m(self, map_func)\u001b[0m\n\u001b[0;32m   1835\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1836\u001b[0m     \"\"\"\n\u001b[1;32m-> 1837\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mFlatMapDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1838\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1839\u001b[0m   def interleave(self,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_dataset, map_func)\u001b[0m\n\u001b[0;32m   4282\u001b[0m     \u001b[1;34m\"\"\"See `Dataset.flat_map()` for details.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4283\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_input_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4284\u001b[1;33m     self._map_func = StructuredFunctionWrapper(\n\u001b[0m\u001b[0;32m   4285\u001b[0m         map_func, self._transformation_name(), dataset=input_dataset)\n\u001b[0;32m   4286\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_map_func\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDatasetSpec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[0;32m   3523\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3524\u001b[0m         \u001b[1;31m# TODO(b/141462134): Switch to using garbage collection.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3525\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_concrete_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3526\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3527\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3049\u001b[0m       \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0minputs\u001b[0m \u001b[0mto\u001b[0m \u001b[0mspecialize\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3050\u001b[0m     \"\"\"\n\u001b[1;32m-> 3051\u001b[1;33m     graph_function = self._get_concrete_function_garbage_collected(\n\u001b[0m\u001b[0;32m   3052\u001b[0m         *args, **kwargs)\n\u001b[0;32m   3053\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3017\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3018\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3019\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3020\u001b[0m       \u001b[0mseen_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3021\u001b[0m       captured = object_identity.ObjectIdentitySet(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3361\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3194\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3195\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3196\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3197\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3198\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   1029\u001b[0m         if x is not None)\n\u001b[0;32m   1030\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1031\u001b[1;33m     \u001b[0mfunc_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariables\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvariables\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1032\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1033\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0madd_control_dependencies\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\auto_control_deps.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, unused_type, unused_value, unused_traceback)\u001b[0m\n\u001b[0;32m    445\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m       \u001b[1;31m# Ensure ordering of collective ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 447\u001b[1;33m       \u001b[0mmanager_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcollective_manager_ids_from_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    448\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mmanager_id\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmanager_ids\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    449\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmanager_id\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcollective_manager_scopes_opened\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\auto_control_deps.py\u001b[0m in \u001b[0;36mcollective_manager_ids_from_op\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m    150\u001b[0m     \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mCollectiveManager\u001b[0m \u001b[0mIDs\u001b[0m \u001b[0mused\u001b[0m \u001b[0mby\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m   \"\"\"\n\u001b[1;32m--> 152\u001b[1;33m   \u001b[1;32mif\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"CollectiveReduce\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"_collective_manager_id\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mtype\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2422\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2423\u001b[0m     \u001b[1;34m\"\"\"The type of the op (e.g. `\"MatMul\"`).\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2424\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_OperationOpType\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2425\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2426\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#function for the main training loop\n",
    "batch_size = 32\n",
    "current_episode = 0\n",
    "num_of_episodes = 5000\n",
    "save_model_every = 50\n",
    "verbose = True\n",
    "\n",
    "for episode in range(current_episode, num_of_episodes):\n",
    "\n",
    "    #start game\n",
    "    ttt = TicTacToe()\n",
    "\n",
    "    #select current player \n",
    "    rand_choice = np.random.randint(1, 3, size = 1) #if 1 computer plays first if 2 computer plays second\n",
    "    if rand_choice == 1:\n",
    "        computer = 'X'\n",
    "    else:\n",
    "        computer = 'O'\n",
    "\n",
    "    #current state\n",
    "    cp = 1 if ttt.current_player == 'X' else 2 #since this is the beginning current player is passed on to the first state representation\n",
    "    state = train.board_state_int(ttt.board, cp)\n",
    "\n",
    "    #append current states and moves\n",
    "    current_game_states, moves = [], []  \n",
    "    current_game_states.append(state)\n",
    "\n",
    "\n",
    "    #bool to start game and break the loop\n",
    "    play_game = True\n",
    "\n",
    "    while play_game:\n",
    "\n",
    "        if np.random.rand() <= epsilon:\n",
    "            all_avail = []\n",
    "            for row, my_list in enumerate(ttt.board):\n",
    "                all_avail.extend((row, index) for index, value in enumerate(my_list) if value == ' ')\n",
    "            move = random.choice(all_avail)\n",
    "\n",
    "        else:\n",
    "            with tf.device(device):\n",
    "                q_preds = model.predict(state[np.newaxis, :])\n",
    "            move_int = np.argmax(q_preds)\n",
    "\n",
    "            #get the cell from the move integer predicted by the model\n",
    "            move = train.int_to_cell_dict[move_int]\n",
    "\n",
    "\n",
    "        if ttt.make_move(move[0], move[1]):\n",
    "            #store data\n",
    "            next_player = 2 if ttt.current_player == 'X' else 1\n",
    "            state = train.board_state_int(ttt.board, next_player)\n",
    "            current_game_states.append(state)\n",
    "            moves.append(move)\n",
    "\n",
    "            if ttt.check_winner():\n",
    "                winner = ttt.winner\n",
    "                break\n",
    "            if all(cell != ' ' for row in ttt.board for cell in row):\n",
    "                winner = 'draw'\n",
    "                break\n",
    "\n",
    "            ttt.current_player = 'O' if ttt.current_player == 'X' else 'X'\n",
    "\n",
    "    #training loop\n",
    "    if len(memory) >= batch_size:\n",
    "\n",
    "        memory_list = list(memory)\n",
    "        random.shuffle(memory_list)\n",
    "\n",
    "        #train the model over the current states\n",
    "        for start_idx in range(0, len(memory_list), batch_size):\n",
    "\n",
    "            end_idx = min(start_idx + batch_size, len(memory_list))\n",
    "            mini_batch = memory_list[start_idx:end_idx]\n",
    "\n",
    "            inputs = tf.zeros((end_idx - start_idx, state.shape[0], state.shape[1], state.shape[2]))\n",
    "            outputs = tf.zeros((end_idx - start_idx, 9)) #9 is the number of values\n",
    "\n",
    "            #get stuff from the mini batch and get qu values and stuff\n",
    "            for i, (cs, ns, mv, r) in enumerate(mini_batch):\n",
    "                with tf.device(device):\n",
    "                    q_value = r + gamma * tf.reduce_max(model.predict(ns[np.newaxis, :]))\n",
    "                    #predicted q values\n",
    "                    pred_q_values = model.predict(cs[np.newaxis, :])\n",
    "\n",
    "                #add the new q value\n",
    "                move_int = train.cell_to_int_dict[mv]\n",
    "                pred_q_values[0][move_int] = q_value\n",
    "                \n",
    "                inputs = tf.tensor_scatter_nd_update(inputs, [[i]], [cs])  \n",
    "                outputs = tf.tensor_scatter_nd_update(outputs, [[i]], [pred_q_values.ravel()]) \n",
    "\n",
    "\n",
    "            model.fit(inputs, outputs, verbose = 0, epochs = 1)\n",
    "            \n",
    "    # assign rewards. If match is drawn either way reward is '0'. If computer choose to play 'X' and winner is 'O' then reward is '-1' vise versa.\n",
    "    if winner == 'draw':\n",
    "        reward = 0\n",
    "    else:\n",
    "        if winner == computer:\n",
    "            reward = reward_value\n",
    "        else:\n",
    "            reward = -reward_value\n",
    "\n",
    "    for i in range(0, len(current_game_states) - 1):\n",
    "        memory.append((current_game_states[i], current_game_states[i + 1], moves[i], reward))\n",
    "\n",
    "    #save the model\n",
    "    if episode % save_model_every == 0:\n",
    "\n",
    "        #save model\n",
    "        save_path = os.path.join(save_dir, f'model_weight_episode_{episode}.h5')\n",
    "        model.save_weights(save_path)\n",
    "\n",
    "        #save memory\n",
    "        filename = os.path.join(save_dir, f\"memory_episode_{episode}.pkl\")\n",
    "\n",
    "        with open(filename, 'wb') as file:\n",
    "            pickle.dump(memory, file)\n",
    "\n",
    "    if episode % 10 == 0 and verbose:\n",
    "        print(f\"current episode: {episode}\")        \n",
    "        #predict using the model\n",
    "        samp1_qs = model.predict(sample_state_1[np.newaxis, :])\n",
    "        print(f\"sample one: {np.argmax(samp1_qs)} max q val = {np.max(samp1_qs)}\")\n",
    "        samp2_qs = model.predict(sample_state_2[np.newaxis, :])\n",
    "        print(f\"sample two: {np.argmax(samp2_qs)} max q val = {np.max(samp2_qs)}\")\n",
    "        \n",
    "    \n",
    "#     if epsilon > epsilon_min:\n",
    "#         epsilon -= epsilon_decay\n",
    "#     else:\n",
    "#         epsilon = epsilon_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7cd54425",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'memory_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-ac873ba52e8c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmemory_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'memory_list' is not defined"
     ]
    }
   ],
   "source": [
    "memory_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "428ae621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| X | O |   |\n",
      "| X | O |   |\n",
      "|   |   |   |\n"
     ]
    }
   ],
   "source": [
    "#print out some states and the responses by the model\n",
    "#example state\n",
    "ttt = TicTacToe()\n",
    "ttt.play_move(0, 0, False)\n",
    "ttt.play_move(0, 1, False)\n",
    "ttt.play_move(1, 0, False)\n",
    "ttt.play_move(1, 1, True)\n",
    "\n",
    "sample_state_1 = train.board_state_int(ttt.board, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6d3d08e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 66.785446, -44.155228,  73.89841 ,  62.885788,  80.92904 ,\n",
       "        -45.862656,  61.43506 ,  71.311646,  55.52045 ]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(sample_state_1[np.newaxis, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db56689f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
